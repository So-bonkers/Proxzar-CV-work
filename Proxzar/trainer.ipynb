{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54966228-40f2-415f-ac3d-247baea2ea45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from patchify import patchify\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping\n",
    "from keras import layers\n",
    "from keras import models, optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from PIL import UnidentifiedImageError  # Import UnidentifiedImageError explicitly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "957b8dc9-70c7-404c-8a2f-4c800dcd2f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters dictionary\n",
    "hp = {}\n",
    "hp[\"image_size\"] = 256\n",
    "hp[\"num_channels\"] = 3 \n",
    "hp[\"patch_size\"] = 32\n",
    "hp[\"num_patches\"] = (hp[\"image_size\"]**2) // (hp[\"patch_size\"]**2)\n",
    "hp[\"flat_patches_shape\"] = (hp[\"num_patches\"], hp[\"patch_size\"]*hp[\"patch_size\"]*hp[\"num_channels\"])\n",
    "\n",
    "hp[\"batch_size\"] = 32\n",
    "hp[\"learning_rate\"] = 1e-4\n",
    "hp[\"num_epochs\"] = 500\n",
    "hp[\"num_classes\"] = 7\n",
    "hp[\"class_names\"] = [\"gutters\",\"roofing\",\"insulation\",\"waterproofing\",\"tools-equipment\",\"siding\",\"building-materials\"]\n",
    "\n",
    "hp[\"num_layers\"] = 12\n",
    "hp[\"hidden_dim\"] = 768\n",
    "hp[\"mlp_dim\"] = 3072\n",
    "hp[\"num_heads\"] = 12\n",
    "hp[\"dropout_rate\"] = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c9abe371-d0f7-41be-b272-c2f27be18f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hp keys: dict_keys(['image_size', 'num_channels', 'patch_size', 'num_patches', 'flat_patches_shape', 'batch_size', 'learning_rate', 'num_epochs', 'num_classes', 'class_names', 'num_layers', 'hidden_dim', 'mlp_dim', 'num_heads', 'dropout_rate'])\n",
      "Batch size: 32\n",
      "Flat patches shape:  (64, 3072)\n",
      "Number of patches:  64\n"
     ]
    }
   ],
   "source": [
    "print(\"hp keys:\", hp.keys())  # Check all keys in hp\n",
    "print(\"Batch size:\", hp.get(\"batch_size\"))  # Check the value associated with \"batch_size\"\n",
    "print(\"Flat patches shape: \", hp.get(\"flat_patches_shape\"))\n",
    "print(\"Number of patches: \", hp.get(\"num_patches\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d508a9e8-688e-4eae-ba09-2302660772f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3b2cec6-428a-40ae-adae-3532a9771271",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path, split=0.1):\n",
    "    images = shuffle(glob(os.path.join(path, \"*\", \"*.jpg\")))\n",
    "\n",
    "    split_size = int(len(images) * split)\n",
    "    train_x, valid_x = train_test_split(images, test_size=split_size, random_state=42)\n",
    "    train_x, test_x = train_test_split(train_x, test_size=split_size, random_state=42)\n",
    "\n",
    "    return train_x, valid_x, test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59e255bd-dde0-4ba9-a5af-65a6f2c8439e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image_label(path):\n",
    "    # Reading Images\n",
    "    path = path.decode()\n",
    "    image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image, (hp[\"image_size\"], hp[\"image_size\"]))\n",
    "    image = image/255.0\n",
    "    \n",
    "    # print(\"Image shape is: \", image.shape)\n",
    "    # cv2.imwrite(f\"files/original_image.jpg\", image)\n",
    "\n",
    "    # Preprocessing to patches\n",
    "    patch_shape = (hp[\"patch_size\"], hp[\"patch_size\"], hp[\"num_channels\"])\n",
    "    patches = patchify(image, patch_shape, hp[\"patch_size\"])\n",
    "\n",
    "    # patches = np.reshape(patches, (64,32,32,3))\n",
    "    # print(\"Patches shape is: \", patches.shape)\n",
    "    # for i in range(64):\n",
    "    #     cv2.imwrite(f\"files/{i}.png\", patches[i])\n",
    "\n",
    "    patches = np.reshape(patches, hp[\"flat_patches_shape\"])\n",
    "    patches = patches.astype(np.float32)\n",
    "\n",
    "    # Label\n",
    "    # print(path)\n",
    "    class_name = path.split(\"/\")[-2]\n",
    "    # print(\"Class name: \",class_name)\n",
    "    class_index = hp[\"class_names\"].index(class_name)\n",
    "    class_index = np.array(class_index, dtype=np.int32)\n",
    "    # print(\"Class Index: \", class_index)\n",
    "\n",
    "    return patches, class_index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99d502b8-ef44-40c1-a05b-80ab4538ce26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "    patches, labels = tf.numpy_function(process_image_label, [path], [tf.float32, tf.int32])\n",
    "    labels = tf.one_hot(labels, hp[\"num_classes\"])\n",
    "\n",
    "    patches.set_shape(hp[\"flat_patches_shape\"])\n",
    "    labels.set_shape(hp[\"num_classes\"])\n",
    "\n",
    "    return patches, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28845d55-1b38-4214-a9b5-4355e1cd6a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_dataset(images, batch=32):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((images))\n",
    "    ds = ds.map(parse).batch(batch).prefetch(8)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a037ffcd-c830-470e-ba57-09cbdf3bf974",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a256dc89-8c94-4d49-ab0e-24ba4bf881b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 31261 - Valid: 3907 - Test: 3907\n",
      "(32, 64, 3072)\n",
      "(32, 7)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Seeding\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "    # Directory for storing files\n",
    "    create_dir(\"files\")\n",
    "\n",
    "    # Paths\n",
    "    dataset_path = \"/home/sksystem/Downloads/Proxzar-CV-work-main/Final_folder_for_classification\"\n",
    "    model_path = os.path.join(\"files\", \"model.h5\")\n",
    "    csv_path = os.path.join(\"files\", \"log.csv\")\n",
    "\n",
    "    # Dataset\n",
    "    train_x, valid_x, test_x = load_data(dataset_path)\n",
    "    print(f\"Train: {len(train_x)} - Valid: {len(valid_x)} - Test: {len(test_x)}\")\n",
    "\n",
    "    # process_image_label(train_x[0])\n",
    "\n",
    "    \n",
    "    train_ds = tf_dataset(train_x, batch = hp[\"batch_size\"])\n",
    "    valid_ds = tf_dataset(valid_x, batch = hp[\"batch_size\"])\n",
    "\n",
    "    for x, y in train_ds.take(1):\n",
    "        print(x.shape)\n",
    "        print(y.shape)\n",
    "\n",
    "    # # Model\n",
    "    # model = ViT(hp)\n",
    "    # model.compile(\n",
    "    #     loss=\"categorical_crossentropy\",\n",
    "    #     optimizer = tf.keras.optimizers.Adam(hp[\"lr\"], clipvalue=1.0),\n",
    "    #     metrics=[\"acc\"]\n",
    "    # )\n",
    "\n",
    "    # # Train the model with tqdm progress bar\n",
    "    # with tqdm(total=hp[\"num_epochs\"], desc=\"Training\") as pbar:\n",
    "    #     for epoch in range(hp[\"num_epochs\"]):\n",
    "    #         model.fit(\n",
    "    #             train_ds,\n",
    "    #             epochs=1,  # Train for 1 epoch at a time\n",
    "    #             validation_data=valid_ds,\n",
    "    #             verbose=0  # Set verbose to 0 to suppress TensorFlow's progress bar\n",
    "    #         )\n",
    "    #         pbar.update(1)  # Update tqdm progress bar for each epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319867c8-bf9b-4eab-84cd-186d2c626c2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
